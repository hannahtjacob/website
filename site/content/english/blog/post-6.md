---
title: "Run k8sgpt with Local LLM"
date: 2023-09-14T12:05:16+06:00
image: "images/showcase/k8sgptllm.png"
description : "A tutorial from Peter Pan to setup on-premise open source LLM for k8sgpt"
draft: false
---


For some cases, you may need on-premise LLM(Large Language Model) deployment instead of OpenAI: to leverage existing GPU, or to ensure total data ownership, or use your fine-tune models.

Now a new tutorial is here! In this tutorial, @panpan0000 will show us how to setup open source LLM like LLaMA locally, and tells k8sgpt to get the "explanation" from the on-premise LLM.

You can find the tutorial [here](https://medium.com/@panpan0000/empower-kubernetes-with-k8sgpt-using-open-source-llm-1b3fa021abd6)

